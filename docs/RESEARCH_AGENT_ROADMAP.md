# Research Agent æ¼”è¿›è·¯çº¿å›¾

## ğŸ“Š å½“å‰èƒ½åŠ›åˆ†æ

### ç°æœ‰å®ç° (deer_code/agents/research_agent.py)

**æ ¸å¿ƒç»„ä»¶ï¼š**
- å•ä¸€å·¥å…·ï¼š`tavily_search_tool`ï¼ˆTavily APIï¼‰
- çŠ¶æ€ç®¡ç†ï¼š`MessagesState`ï¼ˆæ— è‡ªå®šä¹‰çŠ¶æ€ï¼‰
- æ¶æ„ï¼šç®€å•çš„ ReAct agentï¼ˆé€šè¿‡ `create_agent`ï¼‰
- æç¤ºè¯ï¼šåŸºç¡€çš„æœç´¢-æ€»ç»“æ¨¡å¼

**å½“å‰èƒ½åŠ›ï¼š**
1. âœ… åŸºç¡€ Web æœç´¢ï¼ˆTavilyï¼‰
2. âœ… æœç´¢ç»“æœæ ¼å¼åŒ–
3. âœ… ç®€å•çš„æŸ¥è¯¢-å“åº”æ¨¡å¼
4. âœ… å¯é…ç½®æœç´¢æ·±åº¦ï¼ˆbasic/advancedï¼‰
5. âœ… MCP å·¥å…·æ‰©å±•æ”¯æŒ

**ä¸»è¦é™åˆ¶ï¼š**
1. âŒ æ— æŸ¥è¯¢åˆ†è§£èƒ½åŠ›
2. âŒ æ— å¤šæ­¥æ¨ç†æœºåˆ¶
3. âŒ å•ä¸€æœç´¢æºï¼ˆä»… Tavilyï¼‰
4. âŒ æ— å¼•ç”¨ç®¡ç†å’ŒæºéªŒè¯
5. âŒ æ—  PDF/æ–‡æ¡£åˆ†æ
6. âŒ æ— ç ”ç©¶çŠ¶æ€è·Ÿè¸ª
7. âŒ æ— åæ€å’Œè´¨é‡è¯„ä¼°
8. âŒ æ— ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ
9. âŒ æ— äººæœºåä½œæœºåˆ¶

---

## ğŸŒ ä¸šç•Œæ ‡å‡†èƒ½åŠ›å¯¹æ¯”

### Deep Research Agent æ ¸å¿ƒèƒ½åŠ›çŸ©é˜µ

åŸºäºå¯¹ 2025 å¹´ä¸šç•Œæ ‡å‡†çš„ç ”ç©¶ï¼ˆOpenAI Deep Researchã€Microsoft Researcherã€Google ADKã€å„ç±»å¼€æºå®ç°ï¼‰ï¼Œæ ‡å‡† Deep Research Agent åº”å…·å¤‡ï¼š

| èƒ½åŠ›åˆ†ç±» | å…·ä½“èƒ½åŠ› | DeerCode ç°çŠ¶ | ä¸šç•Œæ ‡å‡† |
|---------|---------|--------------|---------|
| **æŸ¥è¯¢å¤„ç†** | æŸ¥è¯¢åˆ†è§£ï¼ˆQuery Decompositionï¼‰ | âŒ | âœ… åˆ†è§£ä¸º 3-7 ä¸ªå­æŸ¥è¯¢ |
| | æŸ¥è¯¢ä¼˜åŒ–ï¼ˆQuery Refinementï¼‰ | âŒ | âœ… åŸºäºç»“æœè¿­ä»£ä¼˜åŒ– |
| | ä¸Šä¸‹æ–‡ä¿æŒï¼ˆContext Retentionï¼‰ | âš ï¸ ä»…æ¶ˆæ¯å†å² | âœ… ä¸“é—¨çŠ¶æ€ç®¡ç† |
| **ä¿¡æ¯æ£€ç´¢** | å¤šæºæœç´¢ | âŒ ä»… Tavily | âœ… Web+arXiv+Scholar+GitHub |
| | å¤šè·³æ£€ç´¢ï¼ˆMulti-hop Retrievalï¼‰ | âŒ | âœ… è¿­ä»£å¼æ·±åº¦æœç´¢ |
| | PDF/æ–‡æ¡£åˆ†æ | âŒ | âœ… ä¸‹è½½å¹¶åˆ†æ PDF |
| | ç»“æœæ’åºå’Œè¿‡æ»¤ | âš ï¸ ä¾èµ– Tavily | âœ… è‡ªä¸»ç›¸å…³æ€§è¯„åˆ† |
| **æ¨ç†ä¸è§„åˆ’** | å¤šæ­¥æ¨ç†ï¼ˆMulti-step Reasoningï¼‰ | âŒ | âœ… åŠ¨æ€æ¨ç†é“¾ |
| | è‡ªé€‚åº”è§„åˆ’ï¼ˆAdaptive Planningï¼‰ | âŒ | âœ… é•¿æœŸè§„åˆ’+å›æº¯ |
| | åæ€æœºåˆ¶ï¼ˆReflectionï¼‰ | âŒ | âœ… è´¨é‡è¯„ä¼°+ç»§ç»­å†³ç­– |
| **è´¨é‡ä¿è¯** | å¼•ç”¨ç®¡ç†ï¼ˆCitation Managementï¼‰ | âŒ | âœ… è‡ªåŠ¨å¼•ç”¨+å¯éªŒè¯é“¾æ¥ |
| | äº‹å®æ ¸æŸ¥ï¼ˆFact-Checkingï¼‰ | âŒ | âœ… å¤šæºäº¤å‰éªŒè¯ |
| | æºå¯ä¿¡åº¦è¯„åˆ† | âŒ | âœ… å¯ä¿¡åº¦æ‰“åˆ† |
| | å¹»è§‰æ£€æµ‹ | âŒ | âœ… RAG + æºçº¦æŸ |
| **è¾“å‡ºç”Ÿæˆ** | ç»“æ„åŒ–æŠ¥å‘Š | âŒ | âœ… Markdown æŠ¥å‘Š+ç« èŠ‚ |
| | å¼•ç”¨è¿½è¸ª | âŒ | âœ… å¯ç‚¹å‡»æºé“¾æ¥ |
| | å¤šè¯­è¨€æ”¯æŒ | âš ï¸ ä¾èµ–æ¨¡å‹ | âœ… æ˜ç¡®å¤šè¯­è¨€ |
| **åä½œä¸ç›‘ç£** | äººæœºåä½œï¼ˆHuman-in-the-loopï¼‰ | âŒ | âœ… Checkpoint æœºåˆ¶ |
| | ä¸­é—´ç»“æœå±•ç¤º | âš ï¸ å·¥å…·è°ƒç”¨å¯è§ | âœ… ç»“æ„åŒ–è¿›åº¦æŠ¥å‘Š |
| | å¯è§£é‡Šæ€§ | âš ï¸ åŸºç¡€ | âœ… æ¨ç†è·¯å¾„å¯è§†åŒ– |
| **æ‰©å±•æ€§** | å¤šæ™ºèƒ½ä½“æ¶æ„ | âŒ å•ä¸€ Agent | âœ… Master+ä¸“é—¨ Agents |
| | å·¥å…·ç”Ÿæ€ç³»ç»Ÿ | âœ… MCP æ”¯æŒ | âœ… MCP + ä¸“é—¨å·¥å…· |
| | è‡ªå®šä¹‰æ£€ç´¢å™¨ | âŒ | âœ… å¯æ’æ‹”æ£€ç´¢å™¨ |

**ç»¼åˆè¯„åˆ†ï¼š** DeerCode Research Agent çº¦å®ç°ä¸šç•Œæ ‡å‡†çš„ **15-20%** èƒ½åŠ›

---

## ğŸ¯ æ¼”è¿›è·¯çº¿å›¾

### é˜¶æ®µä¸€ï¼šæ ¸å¿ƒèƒ½åŠ›å¢å¼ºï¼ˆ1-2 å‘¨ï¼‰ğŸ”¥ ä¼˜å…ˆçº§ï¼šé«˜

**ç›®æ ‡ï¼š** å®ç°åŸºç¡€çš„å¤šæ­¥ç ”ç©¶èƒ½åŠ›

#### 1.1 çŠ¶æ€ç®¡ç†å‡çº§
```python
# æ–°å»ºï¼šsrc/deer_code/agents/research_state.py
class ResearchAgentState(MessagesState):
    """Research agent state with tracking."""

    # ç ”ç©¶çŠ¶æ€
    main_query: str  # ä¸»æŸ¥è¯¢
    sub_queries: list[dict]  # å­æŸ¥è¯¢åˆ—è¡¨ [{"query": str, "status": str, "results": list}]

    # æ£€ç´¢å†å²
    search_history: list[dict]  # æ‰€æœ‰æœç´¢è®°å½•
    retrieved_sources: list[dict]  # æºåˆ—è¡¨ [{"url": str, "title": str, "relevance": float}]

    # ç ”ç©¶è¿›åº¦
    research_depth: int = 0  # å½“å‰æ·±åº¦ï¼ˆ0-3ï¼‰
    max_depth: int = 3  # æœ€å¤§æ·±åº¦

    # è´¨é‡æ§åˆ¶
    confidence_score: float = 0.0  # ç»“æœç½®ä¿¡åº¦
    needs_more_info: bool = True  # æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
```

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/agents/research_agent.py` - æ›´æ–°ä¸ºä½¿ç”¨ `ResearchAgentState`
- `src/deer_code/agents/state.py` - å¯¼å‡ºæ–°çŠ¶æ€ç±»

#### 1.2 æŸ¥è¯¢åˆ†è§£å·¥å…·
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/query_decomposition.py
@tool("decompose_query", parse_docstring=True)
def decompose_query_tool(runtime: ToolRuntime, main_query: str, num_sub_queries: int = 5):
    """
    å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢ä»¥è¿›è¡Œæ·±åº¦ç ”ç©¶ã€‚

    Args:
        runtime: Agent runtime context
        main_query: ä¸»ç ”ç©¶é—®é¢˜
        num_sub_queries: ç”Ÿæˆçš„å­æŸ¥è¯¢æ•°é‡ï¼ˆ3-7ï¼‰

    Returns:
        JSON æ ¼å¼çš„å­æŸ¥è¯¢åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ¯ä¸ªå­æŸ¥è¯¢çš„æœç´¢ç­–ç•¥
    """
    # ä½¿ç”¨ LLM åˆ†è§£æŸ¥è¯¢
    # è¿”å›ç»“æ„åŒ–çš„å­æŸ¥è¯¢è®¡åˆ’
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/` ç›®å½•
- æ–°å»º `src/deer_code/tools/research/query_decomposition.py`
- æ–°å»º `src/deer_code/tools/research/__init__.py`

#### 1.3 åæ€ä¸è¯„ä¼°å·¥å…·
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/reflection.py
@tool("evaluate_research_quality", parse_docstring=True)
def evaluate_research_quality_tool(
    runtime: ToolRuntime,
    gathered_info: str,
    original_query: str
) -> str:
    """
    è¯„ä¼°å½“å‰æ”¶é›†ä¿¡æ¯çš„è´¨é‡å’Œå®Œæ•´æ€§ã€‚

    Args:
        runtime: Agent runtime
        gathered_info: å·²æ”¶é›†çš„ä¿¡æ¯æ‘˜è¦
        original_query: åŸå§‹æŸ¥è¯¢

    Returns:
        è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…æ‹¬ç½®ä¿¡åº¦åˆ†æ•°ã€ç¼ºå¤±ä¿¡æ¯ã€æ˜¯å¦éœ€è¦ç»§ç»­æœç´¢
    """
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/reflection.py`

#### 1.4 æç¤ºè¯å‡çº§
æ›´æ–° `src/deer_code/prompts/templates/research_agent.md`ï¼š

**æ–°å¢ç« èŠ‚ï¼š**
- å¤šæ­¥ç ”ç©¶ç­–ç•¥ï¼ˆQuery Decomposition â†’ Search â†’ Evaluate â†’ Continue/Stopï¼‰
- åæ€æœºåˆ¶æŒ‡å¯¼ï¼ˆä½•æ—¶åœæ­¢ã€ä½•æ—¶æ·±å…¥ï¼‰
- çŠ¶æ€ç®¡ç†è¯´æ˜ï¼ˆå¦‚ä½•ä½¿ç”¨ sub_queriesã€search_historyï¼‰

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/prompts/templates/research_agent.md`

#### 1.5 LangGraph å·¥ä½œæµå‡çº§
```python
# ä¿®æ”¹ï¼šsrc/deer_code/agents/research_agent.py
def create_research_agent(plugin_tools: list[BaseTool] = [], **kwargs):
    """åˆ›å»ºæ”¯æŒå¤šæ­¥æ¨ç†çš„ç ”ç©¶ agentã€‚"""

    # å®šä¹‰èŠ‚ç‚¹
    def should_continue(state: ResearchAgentState):
        """å†³å®šæ˜¯å¦ç»§ç»­ç ”ç©¶ã€‚"""
        if state.research_depth >= state.max_depth:
            return "generate_report"
        if not state.needs_more_info:
            return "generate_report"
        return "continue_research"

    # æ„å»ºå›¾
    workflow = StateGraph(ResearchAgentState)
    workflow.add_node("decompose", decompose_query_node)
    workflow.add_node("search", search_node)
    workflow.add_node("reflect", reflection_node)
    workflow.add_node("generate_report", report_node)

    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges("reflect", should_continue)

    return workflow.compile()
```

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/agents/research_agent.py` - é‡æ„ä¸º StateGraph

**äº¤ä»˜ç‰©ï¼š**
- âœ… æ–°çš„çŠ¶æ€ç®¡ç†ï¼ˆResearchAgentStateï¼‰
- âœ… æŸ¥è¯¢åˆ†è§£å·¥å…·
- âœ… åæ€è¯„ä¼°å·¥å…·
- âœ… å¤šæ­¥å·¥ä½œæµï¼ˆLangGraph StateGraphï¼‰
- âœ… æ›´æ–°çš„ç³»ç»Ÿæç¤ºè¯

**æµ‹è¯•è¦æ±‚ï¼š**
- å•å…ƒæµ‹è¯•ï¼šæŸ¥è¯¢åˆ†è§£ã€åæ€å·¥å…·
- é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„å¤šæ­¥ç ”ç©¶æµç¨‹
- æµ‹è¯•ç”¨ä¾‹ï¼šå¤æ‚æŸ¥è¯¢ï¼ˆå¦‚"æ¯”è¾ƒ 2025 å¹´ top 3 ä¸ª LLM çš„æ¨ç†èƒ½åŠ›"ï¼‰

---

### é˜¶æ®µäºŒï¼šå¤šæºæ£€ç´¢èƒ½åŠ›ï¼ˆ2-3 å‘¨ï¼‰ğŸ”¥ ä¼˜å…ˆçº§ï¼šé«˜

**ç›®æ ‡ï¼š** æ”¯æŒå¤šç§æ•°æ®æºï¼Œå®ç°çœŸæ­£çš„æ·±åº¦ç ”ç©¶

#### 2.1 å¤šæºæœç´¢å·¥å…·é›†
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/sources/

# arxiv_search.py
@tool("arxiv_search", parse_docstring=True)
def arxiv_search_tool(runtime: ToolRuntime, query: str, max_results: int = 10):
    """æœç´¢ arXiv å­¦æœ¯è®ºæ–‡ã€‚"""
    # ä½¿ç”¨ arxiv Python åŒ…

# scholar_search.py
@tool("scholar_search", parse_docstring=True)
def scholar_search_tool(runtime: ToolRuntime, query: str, max_results: int = 10):
    """æœç´¢ Google Scholarï¼ˆé€šè¿‡ SerpAPI æˆ– scholarlyï¼‰ã€‚"""

# github_search.py
@tool("github_search", parse_docstring=True)
def github_search_tool(runtime: ToolRuntime, query: str, search_type: str = "repositories"):
    """æœç´¢ GitHub ä»“åº“ã€ä»£ç ã€issuesã€‚"""
    # ä½¿ç”¨ GitHub API

# pdf_analyzer.py
@tool("analyze_pdf", parse_docstring=True)
def analyze_pdf_tool(runtime: ToolRuntime, url: str, questions: list[str]):
    """ä¸‹è½½å¹¶åˆ†æ PDF æ–‡æ¡£ã€‚"""
    # ä½¿ç”¨ PyPDF2 + LLM åˆ†æ
```

**æ–°å¢ä¾èµ–ï¼ˆpyproject.tomlï¼‰ï¼š**
```toml
arxiv = "^2.1.0"
scholarly = "^1.7.11"  # æˆ– serpapi
PyGithub = "^2.1.1"
PyPDF2 = "^3.0.1"
pypdf = "^3.17.0"  # æ›´å¥½çš„ PDF è§£æ
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/sources/` ç›®å½•
- æ–°å»º 4 ä¸ªæœç´¢å·¥å…·æ–‡ä»¶
- æ›´æ–° `pyproject.toml`

#### 2.2 æºèšåˆå™¨
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/aggregator.py
@tool("aggregate_sources", parse_docstring=True)
def aggregate_sources_tool(
    runtime: ToolRuntime,
    query: str,
    source_types: list[str] = ["web", "arxiv", "scholar"]
):
    """
    å¹¶è¡Œä»å¤šä¸ªæºæœç´¢å¹¶èšåˆç»“æœã€‚

    Args:
        query: æœç´¢æŸ¥è¯¢
        source_types: è¦ä½¿ç”¨çš„æºç±»å‹åˆ—è¡¨

    Returns:
        èšåˆå¹¶æ’åºçš„ç»“æœï¼Œå¸¦æœ‰æºæ ‡è¯†å’Œç›¸å…³æ€§åˆ†æ•°
    """
    # å¹¶è¡Œè°ƒç”¨å¤šä¸ªæœç´¢å·¥å…·
    # èšåˆã€å»é‡ã€æ’åºç»“æœ
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/aggregator.py`

#### 2.3 é…ç½®æ›´æ–°
```yaml
# config.example.yaml æ–°å¢
tools:
  research:
    sources:
      tavily:
        enabled: true
        api_key: $TAVILY_API_KEY
      arxiv:
        enabled: true
        max_results: 10
      scholar:
        enabled: true
        api_key: $SERPAPI_KEY  # å¯é€‰ï¼Œä½¿ç”¨ scholarly å¯å…è´¹
      github:
        enabled: true
        token: $GITHUB_TOKEN  # å¯é€‰ï¼Œæé«˜ API é™åˆ¶
    pdf_analysis:
      enabled: true
      max_file_size_mb: 50
      cache_dir: ".cache/pdfs"
```

**å½±å“æ–‡ä»¶ï¼š**
- `config.example.yaml` - æ–°å¢ research é…ç½®éƒ¨åˆ†
- `src/deer_code/config/config.py` - å¯èƒ½éœ€è¦æ·»åŠ é…ç½®éªŒè¯

#### 2.4 æ›´æ–° Research Agent
```python
# ä¿®æ”¹ï¼šsrc/deer_code/agents/research_agent.py
def create_research_agent(plugin_tools: list[BaseTool] = [], **kwargs):
    """åˆ›å»ºæ”¯æŒå¤šæºæ£€ç´¢çš„ç ”ç©¶ agentã€‚"""

    # æ ¹æ®é…ç½®å¯ç”¨å·¥å…·
    config = get_config_section(["tools", "research", "sources"])
    tools = []

    if config.get("tavily", {}).get("enabled"):
        tools.append(tavily_search_tool)
    if config.get("arxiv", {}).get("enabled"):
        tools.append(arxiv_search_tool)
    if config.get("scholar", {}).get("enabled"):
        tools.append(scholar_search_tool)
    if config.get("github", {}).get("enabled"):
        tools.append(github_search_tool)

    tools.extend([
        aggregate_sources_tool,
        analyze_pdf_tool,
        decompose_query_tool,
        evaluate_research_quality_tool,
        *plugin_tools,
    ])

    # ... æ„å»º StateGraph
```

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/agents/research_agent.py`

**äº¤ä»˜ç‰©ï¼š**
- âœ… 4 ä¸ªæ–°æœç´¢æºï¼ˆarXiv, Scholar, GitHub, PDFï¼‰
- âœ… æºèšåˆå™¨
- âœ… é…ç½®åŒ–çš„æºå¯ç”¨/ç¦ç”¨
- âœ… æ›´æ–°çš„ research agent

**æµ‹è¯•è¦æ±‚ï¼š**
- å•å…ƒæµ‹è¯•ï¼šæ¯ä¸ªæœç´¢å·¥å…·
- é›†æˆæµ‹è¯•ï¼šå¤šæºèšåˆ
- æµ‹è¯•ç”¨ä¾‹ï¼šéœ€è¦å­¦æœ¯è®ºæ–‡çš„æŸ¥è¯¢ã€éœ€è¦ä»£ç ç¤ºä¾‹çš„æŸ¥è¯¢

---

### é˜¶æ®µä¸‰ï¼šå¼•ç”¨ä¸è´¨é‡ä¿è¯ï¼ˆ1-2 å‘¨ï¼‰ğŸ”¥ ä¼˜å…ˆçº§ï¼šä¸­

**ç›®æ ‡ï¼š** ç¡®ä¿ç ”ç©¶ç»“æœå¯éªŒè¯ã€å¯è¿½æº¯

#### 3.1 å¼•ç”¨ç®¡ç†ç³»ç»Ÿ
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/citation.py
from dataclasses import dataclass
from typing import Literal

@dataclass
class Citation:
    """å¼•ç”¨æ•°æ®ç»“æ„ã€‚"""
    id: str  # å¼•ç”¨ IDï¼ˆå¦‚ [1], [2]ï¼‰
    title: str
    url: str
    source_type: Literal["web", "arxiv", "scholar", "github", "pdf"]
    authors: list[str] = None
    publication_date: str = None
    relevance_score: float = 0.0
    excerpt: str = ""  # å¼•ç”¨çš„å…·ä½“ç‰‡æ®µ

@tool("add_citation", parse_docstring=True)
def add_citation_tool(runtime: ToolRuntime, citation_data: dict):
    """æ·»åŠ å¼•ç”¨åˆ°å½“å‰ç ”ç©¶çŠ¶æ€ã€‚"""

@tool("generate_bibliography", parse_docstring=True)
def generate_bibliography_tool(runtime: ToolRuntime, format: str = "markdown"):
    """
    ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨ã€‚

    Args:
        format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdown, bibtex, apaï¼‰
    """
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/citation.py`

#### 3.2 äº‹å®æ ¸æŸ¥å·¥å…·
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/fact_check.py
@tool("verify_claim", parse_docstring=True)
def verify_claim_tool(
    runtime: ToolRuntime,
    claim: str,
    sources: list[str]
):
    """
    å¯¹æ¯”å¤šä¸ªæºéªŒè¯å£°æ˜çš„çœŸå®æ€§ã€‚

    Args:
        claim: éœ€è¦éªŒè¯çš„å£°æ˜
        sources: ç”¨äºéªŒè¯çš„æº URL åˆ—è¡¨

    Returns:
        éªŒè¯ç»“æœï¼ŒåŒ…æ‹¬ï¼š
        - ä¸€è‡´æ€§åˆ†æ•°
        - æ”¯æŒ/åå¯¹çš„æº
        - å¯ä¿¡åº¦è¯„çº§
    """
    # ä»å¤šä¸ªæºæå–ç›¸å…³ä¿¡æ¯
    # ä½¿ç”¨ LLM å¯¹æ¯”å’Œè¯„ä¼°ä¸€è‡´æ€§
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/fact_check.py`

#### 3.3 æºå¯ä¿¡åº¦è¯„åˆ†
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/credibility.py
CREDIBILITY_SCORES = {
    # å­¦æœ¯æº
    "arxiv.org": 0.95,
    "scholar.google.com": 0.90,
    "ieee.org": 0.95,
    "acm.org": 0.95,

    # å®˜æ–¹æ–‡æ¡£
    "github.com": 0.85,
    "docs.python.org": 0.95,

    # æ–°é—»/åª’ä½“ï¼ˆéœ€è¦æ›´ç»†ç²’åº¦ï¼‰
    "reuters.com": 0.85,
    "nature.com": 0.95,

    # é»˜è®¤
    "default": 0.50,
}

@tool("evaluate_source_credibility", parse_docstring=True)
def evaluate_source_credibility_tool(runtime: ToolRuntime, url: str):
    """è¯„ä¼°ä¿¡æ¯æºçš„å¯ä¿¡åº¦ã€‚"""
    # åŸºäºåŸŸåã€HTTPSã€å†…å®¹ç±»å‹ç­‰è¯„åˆ†
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/credibility.py`

#### 3.4 æ›´æ–°çŠ¶æ€ç®¡ç†
```python
# ä¿®æ”¹ï¼šsrc/deer_code/agents/research_state.py
class ResearchAgentState(MessagesState):
    # ... ç°æœ‰å­—æ®µ

    # å¼•ç”¨ç®¡ç†ï¼ˆæ–°å¢ï¼‰
    citations: list[Citation] = []  # æ‰€æœ‰å¼•ç”¨
    citation_map: dict[str, str] = {}  # {content_hash: citation_id}

    # è´¨é‡æ§åˆ¶ï¼ˆæ–°å¢ï¼‰
    verified_claims: list[dict] = []  # å·²éªŒè¯çš„å£°æ˜
    credibility_scores: dict[str, float] = {}  # {url: score}
```

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/agents/research_state.py`

**äº¤ä»˜ç‰©ï¼š**
- âœ… å¼•ç”¨ç®¡ç†ç³»ç»Ÿï¼ˆCitation ç±» + å·¥å…·ï¼‰
- âœ… äº‹å®æ ¸æŸ¥å·¥å…·
- âœ… æºå¯ä¿¡åº¦è¯„åˆ†
- âœ… æ›´æ–°çš„çŠ¶æ€ç®¡ç†

**æµ‹è¯•è¦æ±‚ï¼š**
- å•å…ƒæµ‹è¯•ï¼šå¼•ç”¨æ ¼å¼åŒ–ã€å¯ä¿¡åº¦è¯„åˆ†
- é›†æˆæµ‹è¯•ï¼šç«¯åˆ°ç«¯å¼•ç”¨è¿½è¸ª
- æµ‹è¯•ç”¨ä¾‹ï¼šç”Ÿæˆå¸¦å®Œæ•´å¼•ç”¨çš„ç ”ç©¶æŠ¥å‘Š

---

### é˜¶æ®µå››ï¼šæŠ¥å‘Šç”Ÿæˆä¸äººæœºåä½œï¼ˆ1-2 å‘¨ï¼‰ğŸ”¥ ä¼˜å…ˆçº§ï¼šä¸­

**ç›®æ ‡ï¼š** ç”Ÿæˆé«˜è´¨é‡çš„ç»“æ„åŒ–æŠ¥å‘Šï¼Œæ”¯æŒäººç±»ç›‘ç£

#### 4.1 æŠ¥å‘Šç”Ÿæˆå™¨
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/report.py
@tool("generate_research_report", parse_docstring=True)
def generate_research_report_tool(
    runtime: ToolRuntime,
    title: str,
    sections: list[str] = ["summary", "key_findings", "detailed_analysis", "conclusion"],
    include_citations: bool = True,
    output_format: str = "markdown"
):
    """
    ç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Šã€‚

    Args:
        title: æŠ¥å‘Šæ ‡é¢˜
        sections: åŒ…å«çš„ç« èŠ‚
        include_citations: æ˜¯å¦åŒ…å«å‚è€ƒæ–‡çŒ®
        output_format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdown, html, pdfï¼‰

    Returns:
        æ ¼å¼åŒ–çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
        - æ‰§è¡Œæ‘˜è¦
        - åˆ†ç« èŠ‚çš„å‘ç°
        - å¼•ç”¨é“¾æ¥ï¼ˆå¯ç‚¹å‡»ï¼‰
        - å‚è€ƒæ–‡çŒ®åˆ—è¡¨
    """
    state: ResearchAgentState = runtime.state

    # ä½¿ç”¨ Jinja2 æ¨¡æ¿
    template = """
# {{ title }}

*ç”Ÿæˆæ—¶é—´ï¼š{{ timestamp }}*
*ä¸»æŸ¥è¯¢ï¼š{{ main_query }}*

## æ‰§è¡Œæ‘˜è¦
{{ summary }}

{% for section in sections %}
## {{ section.title }}
{{ section.content }}

{% if section.citations %}
**å‚è€ƒèµ„æ–™ï¼š**
{% for cite in section.citations %}
- [{{ cite.id }}] {{ cite.title }} - [é“¾æ¥]({{ cite.url }})
{% endfor %}
{% endif %}
{% endfor %}

## å‚è€ƒæ–‡çŒ®
{% for citation in all_citations %}
[{{ citation.id }}] {{ citation.title }}
ä½œè€…ï¼š{{ citation.authors | join(", ") }}
æ¥æºï¼š{{ citation.url }}
ç›¸å…³æ€§ï¼š{{ citation.relevance_score | round(2) }}
{% endfor %}

---
*æœ¬æŠ¥å‘Šç”± DeerCode Research Agent è‡ªåŠ¨ç”Ÿæˆ*
"""
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/report.py`
- æ–°å»º `src/deer_code/tools/research/templates/report_template.md`

#### 4.2 äººæœºåä½œæœºåˆ¶ï¼ˆCheckpointï¼‰
```python
# ä¿®æ”¹ï¼šsrc/deer_code/agents/research_agent.py
from langgraph.checkpoint.memory import MemorySaver

def create_research_agent(
    plugin_tools: list[BaseTool] = [],
    enable_human_in_loop: bool = False,
    **kwargs
):
    """åˆ›å»ºç ”ç©¶ agentï¼Œæ”¯æŒäººæœºåä½œã€‚"""

    # ... æ„å»ºå·¥ä½œæµ

    # æ·»åŠ äººç±»å®¡æ‰¹èŠ‚ç‚¹
    if enable_human_in_loop:
        def human_approval_node(state: ResearchAgentState):
            """ç­‰å¾…äººç±»æ‰¹å‡†ç»§ç»­ç ”ç©¶ã€‚"""
            # æ˜¾ç¤ºå½“å‰è¿›åº¦å’Œå‘ç°
            # ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼šcontinue / stop / modify_query
            pass

        workflow.add_node("human_approval", human_approval_node)
        workflow.add_edge("reflect", "human_approval")
        workflow.add_conditional_edges(
            "human_approval",
            lambda s: s.user_decision,
            {
                "continue": "search",
                "stop": "generate_report",
                "modify": "decompose",
            }
        )

    # ä½¿ç”¨ checkpoint ä¿å­˜çŠ¶æ€
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)
```

**å½±å“æ–‡ä»¶ï¼š**
- `src/deer_code/agents/research_agent.py`

#### 4.3 TUI é›†æˆï¼ˆå¯é€‰ï¼‰
å¦‚æœè¦åœ¨ Textual TUI ä¸­å±•ç¤ºç ”ç©¶è¿›åº¦ï¼š

```python
# æ–°å»ºï¼šsrc/deer_code/cli/components/research/progress.py
class ResearchProgressView(Widget):
    """æ˜¾ç¤ºç ”ç©¶è¿›åº¦çš„ widgetã€‚"""

    def __init__(self):
        super().__init__()
        self.main_query = ""
        self.sub_queries = []
        self.current_depth = 0
        self.confidence = 0.0

    def render(self) -> RenderableType:
        # æ˜¾ç¤ºï¼š
        # - ä¸»æŸ¥è¯¢
        # - å­æŸ¥è¯¢åˆ—è¡¨ï¼ˆçŠ¶æ€ï¼špending/searching/completedï¼‰
        # - å½“å‰æ·±åº¦
        # - ç½®ä¿¡åº¦åˆ†æ•°
        # - å·²æ£€ç´¢æºæ•°é‡
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/cli/components/research/` ç›®å½•
- æ–°å»º `src/deer_code/cli/components/research/progress.py`
- ä¿®æ”¹ `src/deer_code/cli/app.py`ï¼ˆå¦‚æœè¦é›†æˆï¼‰

**äº¤ä»˜ç‰©ï¼š**
- âœ… æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆJinja2 æ¨¡æ¿ï¼‰
- âœ… äººæœºåä½œæœºåˆ¶ï¼ˆCheckpointï¼‰
- âœ… ï¼ˆå¯é€‰ï¼‰TUI è¿›åº¦å±•ç¤º

**æµ‹è¯•è¦æ±‚ï¼š**
- å•å…ƒæµ‹è¯•ï¼šæŠ¥å‘Šæ ¼å¼åŒ–
- é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„äººæœºåä½œæµç¨‹
- æµ‹è¯•ç”¨ä¾‹ï¼šå¸¦äººç±»å¹²é¢„çš„å¤æ‚ç ”ç©¶ä»»åŠ¡

---

### é˜¶æ®µäº”ï¼šé«˜çº§ç‰¹æ€§ï¼ˆ2-3 å‘¨ï¼‰ğŸ”¥ ä¼˜å…ˆçº§ï¼šä½

**ç›®æ ‡ï¼š** å®ç°å¤šæ™ºèƒ½ä½“ã€å¯è§†åŒ–ç­‰é«˜çº§èƒ½åŠ›

#### 5.1 å¤šæ™ºèƒ½ä½“æ¶æ„
```python
# æ–°å»ºï¼šsrc/deer_code/agents/research/multi_agent.py
from langgraph.graph import StateGraph

class MasterPlannerAgent:
    """ä¸»è§„åˆ’ agentï¼Œåˆ†è§£ä»»åŠ¡å¹¶åè°ƒå­ agentsã€‚"""

class SpecializedSearchAgent:
    """ä¸“é—¨æœç´¢ agentï¼ˆWeb/Academic/Codeï¼‰ã€‚"""

class SynthesisAgent:
    """ç»¼åˆåˆ†æ agentï¼Œèšåˆå¤šä¸ª agent çš„ç»“æœã€‚"""

def create_multi_agent_research_system():
    """åˆ›å»ºå¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿã€‚"""
    workflow = StateGraph(ResearchAgentState)

    # æ·»åŠ  agents ä½œä¸ºèŠ‚ç‚¹
    workflow.add_node("master_planner", MasterPlannerAgent())
    workflow.add_node("web_searcher", SpecializedSearchAgent("web"))
    workflow.add_node("academic_searcher", SpecializedSearchAgent("academic"))
    workflow.add_node("code_searcher", SpecializedSearchAgent("code"))
    workflow.add_node("synthesizer", SynthesisAgent())

    # å®šä¹‰è·¯ç”±é€»è¾‘
    # ...
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/agents/research/` ç›®å½•
- æ–°å»º `src/deer_code/agents/research/multi_agent.py`

#### 5.2 å¯è§†åŒ–å·¥å…·
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/visualization.py
@tool("generate_visualization", parse_docstring=True)
def generate_visualization_tool(
    runtime: ToolRuntime,
    data_type: str,  # "timeline", "comparison_table", "mind_map"
    data: dict
):
    """
    ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚

    æ”¯æŒï¼š
    - æ—¶é—´çº¿ï¼ˆäº‹ä»¶å‘å±•ï¼‰
    - å¯¹æ¯”è¡¨æ ¼ï¼ˆå¤šä¸ªé€‰é¡¹å¯¹æ¯”ï¼‰
    - æ€ç»´å¯¼å›¾ï¼ˆæ¦‚å¿µå…³ç³»ï¼‰
    """
    # ä½¿ç”¨ matplotlib/plotly ç”Ÿæˆå›¾è¡¨
    # ä¿å­˜ä¸ºå›¾ç‰‡æˆ– HTML
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/visualization.py`

#### 5.3 NL2SQLï¼ˆå¯é€‰ï¼‰
å¦‚æœéœ€è¦æŸ¥è¯¢ç»“æ„åŒ–æ•°æ®ï¼š

```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/nl2sql.py
@tool("query_database", parse_docstring=True)
def nl2sql_tool(
    runtime: ToolRuntime,
    natural_language_query: str,
    database_schema: dict
):
    """å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º SQL å¹¶æŸ¥è¯¢æ•°æ®åº“ã€‚"""
    # ä½¿ç”¨ LLM ç”Ÿæˆ SQL
    # å®‰å…¨æ‰§è¡Œï¼ˆåªè¯»æ¨¡å¼ï¼‰
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/nl2sql.py`

#### 5.4 ç¼“å­˜ä¸æ€§èƒ½ä¼˜åŒ–
```python
# æ–°å»ºï¼šsrc/deer_code/tools/research/cache.py
from functools import lru_cache
import hashlib
import pickle

class ResearchCache:
    """æœç´¢ç»“æœç¼“å­˜ã€‚"""

    def __init__(self, cache_dir: str = ".cache/research"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def get(self, query: str, source: str):
        """è·å–ç¼“å­˜çš„æœç´¢ç»“æœã€‚"""
        cache_key = hashlib.md5(f"{query}:{source}".encode()).hexdigest()
        cache_file = self.cache_dir / f"{cache_key}.pkl"

        if cache_file.exists():
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆä¾‹å¦‚ 24 å°æ—¶ï¼‰
            if (time.time() - cache_file.stat().st_mtime) < 86400:
                return pickle.load(cache_file.open("rb"))
        return None

    def set(self, query: str, source: str, results: dict):
        """ç¼“å­˜æœç´¢ç»“æœã€‚"""
        # ...
```

**å½±å“æ–‡ä»¶ï¼š**
- æ–°å»º `src/deer_code/tools/research/cache.py`

**äº¤ä»˜ç‰©ï¼š**
- âœ… å¤šæ™ºèƒ½ä½“æ¶æ„ï¼ˆå¯é€‰ï¼‰
- âœ… å¯è§†åŒ–å·¥å…·
- âœ… NL2SQLï¼ˆå¯é€‰ï¼‰
- âœ… ç»“æœç¼“å­˜

**æµ‹è¯•è¦æ±‚ï¼š**
- æ€§èƒ½æµ‹è¯•ï¼šç¼“å­˜å‘½ä¸­ç‡ã€å“åº”æ—¶é—´
- é›†æˆæµ‹è¯•ï¼šå¤šæ™ºèƒ½ä½“åä½œ

---

## ğŸ“… å®Œæ•´æ—¶é—´çº¿

| é˜¶æ®µ | åŠŸèƒ½ | æ—¶é—´ | ä¼˜å…ˆçº§ | å›¢é˜Ÿè§„æ¨¡ |
|-----|------|------|--------|---------|
| **é˜¶æ®µä¸€** | æ ¸å¿ƒèƒ½åŠ›å¢å¼º | 1-2 å‘¨ | ğŸ”¥ é«˜ | 1 äºº |
| **é˜¶æ®µäºŒ** | å¤šæºæ£€ç´¢ | 2-3 å‘¨ | ğŸ”¥ é«˜ | 1-2 äºº |
| **é˜¶æ®µä¸‰** | å¼•ç”¨ä¸è´¨é‡ | 1-2 å‘¨ | âš ï¸ ä¸­ | 1 äºº |
| **é˜¶æ®µå››** | æŠ¥å‘Šä¸åä½œ | 1-2 å‘¨ | âš ï¸ ä¸­ | 1 äºº |
| **é˜¶æ®µäº”** | é«˜çº§ç‰¹æ€§ | 2-3 å‘¨ | ğŸ’¡ ä½ | 1-2 äºº |
| **æ€»è®¡** | | **7-12 å‘¨** | | |

**æœ€å°å¯è¡Œäº§å“ï¼ˆMVPï¼‰ï¼š** é˜¶æ®µä¸€ + é˜¶æ®µäºŒï¼ˆ3-5 å‘¨ï¼‰
**ç”Ÿäº§å°±ç»ªç‰ˆæœ¬ï¼š** é˜¶æ®µä¸€ ~ é˜¶æ®µå››ï¼ˆ5-9 å‘¨ï¼‰
**å®Œæ•´ç‰ˆæœ¬ï¼š** æ‰€æœ‰é˜¶æ®µï¼ˆ7-12 å‘¨ï¼‰

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

### èƒ½åŠ›æŒ‡æ ‡
- [ ] èƒ½å¤Ÿåˆ†è§£å¤æ‚æŸ¥è¯¢ä¸º 3-7 ä¸ªå­æŸ¥è¯¢
- [ ] æ”¯æŒè‡³å°‘ 4 ä¸ªä¸åŒçš„ä¿¡æ¯æºï¼ˆWeb, arXiv, Scholar, GitHubï¼‰
- [ ] ç”Ÿæˆå¸¦å®Œæ•´å¼•ç”¨çš„ç»“æ„åŒ–æŠ¥å‘Š
- [ ] ç½®ä¿¡åº¦è¯„åˆ†å‡†ç¡®ç‡ > 80%
- [ ] PDF åˆ†ææˆåŠŸç‡ > 90%

### è´¨é‡æŒ‡æ ‡
- [ ] å¼•ç”¨å‡†ç¡®æ€§ï¼š100%ï¼ˆæ— å¹»è§‰å¼•ç”¨ï¼‰
- [ ] æºå¯ä¿¡åº¦æ ‡æ³¨è¦†ç›–ç‡ > 95%
- [ ] å¤šæºä¸€è‡´æ€§éªŒè¯è¦†ç›–é‡è¦å£°æ˜
- [ ] æŠ¥å‘Šç»“æ„æ¸…æ™°åº¦ï¼šç”¨æˆ·æ»¡æ„åº¦ > 4/5

### æ€§èƒ½æŒ‡æ ‡
- [ ] ç®€å•æŸ¥è¯¢å“åº”æ—¶é—´ < 30 ç§’
- [ ] å¤æ‚æŸ¥è¯¢ï¼ˆæ·±åº¦=3ï¼‰å“åº”æ—¶é—´ < 5 åˆ†é’Ÿ
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 40%
- [ ] å¹¶å‘æœç´¢èƒ½åŠ›ï¼šè‡³å°‘ 3 ä¸ªæºå¹¶è¡Œ

### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
- [ ] ç ”ç©¶è¿›åº¦å¯è§†åŒ–
- [ ] æ”¯æŒäººæœºåä½œï¼ˆcheckpointï¼‰
- [ ] ä¸­é—´ç»“æœå¯æŸ¥çœ‹
- [ ] é”™è¯¯æ¢å¤èƒ½åŠ›ï¼ˆé‡è¯•ã€å›é€€ï¼‰

---

## ğŸš§ æŠ€æœ¯å€ºåŠ¡ä¸é£é™©

### å·²çŸ¥é£é™©
1. **API æˆæœ¬ï¼š** å¤šæºæœç´¢ä¼šå¢åŠ  API è°ƒç”¨ï¼ˆSerpAPIã€Tavily ç­‰ï¼‰
   - **ç¼“è§£æªæ–½ï¼š** å®ç°ç¼“å­˜ã€é…ç½®åŒ–æºå¯ç”¨ã€ä½¿ç”¨å…è´¹ APIï¼ˆscholarlyï¼‰

2. **PDF å¤„ç†å¤æ‚æ€§ï¼š** ä¸åŒ PDF æ ¼å¼ã€æ‰«ææ–‡æ¡£
   - **ç¼“è§£æªæ–½ï¼š** OCR æ”¯æŒã€é”™è¯¯å¤„ç†ã€æ–‡ä»¶å¤§å°é™åˆ¶

3. **äº‹å®æ ¸æŸ¥å‡†ç¡®æ€§ï¼š** LLM æœ¬èº«å¯èƒ½äº§ç”Ÿè¯¯åˆ¤
   - **ç¼“è§£æªæ–½ï¼š** å¤šæºäº¤å‰éªŒè¯ã€äººç±»ç›‘ç£ã€æ˜ç¡®ç½®ä¿¡åº¦

4. **æ€§èƒ½é—®é¢˜ï¼š** å¤šæ­¥ç ”ç©¶å¯èƒ½å¾ˆæ…¢
   - **ç¼“è§£æªæ–½ï¼š** å¹¶è¡Œæœç´¢ã€æµå¼è¾“å‡ºã€æ·±åº¦é™åˆ¶

### æŠ€æœ¯å€ºåŠ¡
- å½“å‰ `research_agent.py` è¿‡äºç®€å•ï¼Œéœ€è¦å®Œå…¨é‡æ„
- ç¼ºå°‘ç»Ÿä¸€çš„é”™è¯¯å¤„ç†ç­–ç•¥
- é…ç½®ç®¡ç†éœ€è¦å¢å¼ºï¼ˆéªŒè¯ã€é»˜è®¤å€¼ï¼‰
- æµ‹è¯•è¦†ç›–ç‡éœ€è¦æå‡ï¼ˆå½“å‰ç¼ºå°‘ research agent æµ‹è¯•ï¼‰

---

## ğŸ“š å‚è€ƒèµ„æº

### å­¦æœ¯è®ºæ–‡
1. **Deep Research Agents: A Systematic Examination And Roadmap** (arXiv:2506.18096)
2. **Deep Research: A Survey of Autonomous Research Agents** (arXiv:2508.12752)
3. **Enterprise Deep Research** (arXiv:2510.17797)
4. **Towards Robust Fact-Checking: A Multi-Agent System** (arXiv:2506.17878)

### å¼€æºé¡¹ç›®
- [OpenAI Deep Research](https://openai.com/index/introducing-deep-research/)
- [LangGraph Deep Research Examples](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [Google ADK](https://cloud.google.com/blog/products/ai-machine-learning/build-a-deep-research-agent-with-google-adk)

### å·¥å…·ä¸åº“
- **arxiv** - Python å®¢æˆ·ç«¯ï¼šhttps://github.com/lukasschwab/arxiv.py
- **scholarly** - Google Scholar çˆ¬è™«ï¼šhttps://scholarly.readthedocs.io/
- **PyPDF2** / **pypdf** - PDF è§£æ
- **SerpAPI** - å•†ä¸šæœç´¢ APIï¼ˆGoogle Scholar, Google Searchï¼‰

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

### é˜¶æ®µå®æ–½é¡ºåºå»ºè®®
1. **å…ˆåšé˜¶æ®µä¸€ï¼š** è¿™æ˜¯åŸºç¡€ï¼Œæ‰€æœ‰åç»­åŠŸèƒ½éƒ½ä¾èµ–å®ƒ
2. **å†åšé˜¶æ®µäºŒï¼š** å¤šæºèƒ½åŠ›æ˜¯ "Deep Research" çš„æ ¸å¿ƒå·®å¼‚åŒ–
3. **ç„¶åé˜¶æ®µä¸‰/å››ï¼š** å¼•ç”¨å’ŒæŠ¥å‘Šæ˜¯ç”¨æˆ·ç›´æ¥ä½“éªŒçš„éƒ¨åˆ†
4. **æœ€åé˜¶æ®µäº”ï¼š** å¯é€‰çš„é«˜çº§ç‰¹æ€§ï¼Œå¯æ ¹æ®ç”¨æˆ·åé¦ˆå†³å®šä¼˜å…ˆçº§

### å¼€å‘æ³¨æ„äº‹é¡¹
- æ¯ä¸ªé˜¶æ®µç»“æŸåè¿›è¡Œç”¨æˆ·æµ‹è¯•
- ä¿æŒå‘åå…¼å®¹ï¼ˆæ—§çš„ç®€å• research agent ä»å¯ç”¨ï¼‰
- æ–‡æ¡£å…ˆè¡Œï¼ˆæ¯ä¸ªæ–°å·¥å…·éƒ½è¦æœ‰æ¸…æ™°çš„ docstringï¼‰
- æµ‹è¯•é©±åŠ¨ï¼ˆå…ˆå†™æµ‹è¯•ï¼Œå†å®ç°åŠŸèƒ½ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0
**åˆ›å»ºæ—¶é—´ï¼š** 2025-11-17
**æœ€åæ›´æ–°ï¼š** 2025-11-17
**ä½œè€…ï¼š** DeerCode Development Team
